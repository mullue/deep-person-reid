{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c21599-51c0-40e4-a300-da3c1edc2d6b",
   "metadata": {},
   "source": [
    "## Torchreid getting started\n",
    "- reference : https://kaiyangzhou.github.io/deep-person-reid/\n",
    "\n",
    "터미널에서 다음 명령을 실행한 후 새롭게 생성된 `torchreid` 커널로 본 노트북을 실행합니다.\n",
    "\n",
    "```sh\n",
    "# cd to your preferred directory and clone this repo\n",
    "git clone https://github.com/KaiyangZhou/deep-person-reid.git\n",
    "\n",
    "# create environment\n",
    "cd deep-person-reid/\n",
    "conda create --name torchreid python=3.7\n",
    "conda activate torchreid\n",
    "\n",
    "# install dependencies\n",
    "# make sure `which python` and `which pip` point to the correct path\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# On cpu instance, install torch and torchvision (select the proper cuda version to suit your machine)\n",
    "conda install pytorch-cpu torchvision-cpu -c pytorch\n",
    "\n",
    "# On gpu instance, install torch and torchvision (select the proper cuda version to suit your machine)\n",
    "conda install pytorch torchvision cudatoolkit=9.0 -c pytorch\n",
    "\n",
    "# install torchreid (don't need to re-build it if you modify the source code)\n",
    "python setup.py develop\n",
    "\n",
    "conda install jupyter\n",
    "python -m ipykernel install --name torchreid --user\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cd33a-58f0-4c16-990a-990465dcfbce",
   "metadata": {},
   "source": [
    "#### Step 1: import the Torchreid library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929406b4-ce6c-4b3f-854e-2ed6665624dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchreid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01c62c-7df8-4458-b7f4-b189d90689c4",
   "metadata": {},
   "source": [
    "#### Step 2: construct data manager\n",
    "아래코드는 자동으로 market-1501 데이터를 다운로드합니다.  \n",
    "만약 market-1501 데이터가 다운되지 않을 경우 Kaggle(https://www.kaggle.com/datasets/pengcw1/market-1501) 에서 데이터를 다운받고 다음 경로로 업로드한 후 다음 셀을 다시 실행합니다.\n",
    "\n",
    "```sh\n",
    "./reid-data/market1501\n",
    "```\n",
    "\n",
    "다른 데이터셋을 이용하고자 할 경우 다음 페이지를 참고합니다. -> https://kaiyangzhou.github.io/deep-person-reid/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a46d84-bb38-4dba-8a69-8ce4c3e4858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ random crop (enlarge to 288x144 and crop 256x128)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/deep-person-reid/torchreid/data/datasets/image/market1501.py:38: UserWarning: The current data structure is deprecated. Please put data folders such as \"bounding_box_train\" under \"Market-1501-v15.09.15\".\n",
      "  'The current data structure is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root=\"reid-data\",\n",
    "    sources=\"market1501\",\n",
    "    targets=\"market1501\",\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=32,\n",
    "    batch_size_test=100,\n",
    "    transforms=[\"random_flip\", \"random_crop\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a705e-7314-4bed-b796-dcfd831d9d11",
   "metadata": {},
   "source": [
    "#### Step 3: Construct CNN model and initialise optimiser/learning rate scheduler\n",
    "\n",
    "`resnet50`를 사용하는 pretrained 모델을 사용하도록 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6df962c-f77e-49c0-8923-3752a76e18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"resnet50\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "# model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227d8d8-660d-4db9-8a46-81ce0ed2305a",
   "metadata": {},
   "source": [
    "#### Step 4: construct engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ea5af7-e2bf-419b-9873-4b216e2a30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = torchreid.engine.ImageSoftmaxEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d9960-c816-412a-91ba-e8f040cc683c",
   "metadata": {},
   "source": [
    "#### Step 5: run model training and test\n",
    "\n",
    "테스트 런을 실행합니다.\n",
    "실행시 사용할 수 있는 파라미터는 다음과 같습니다.\n",
    "- save_dir (str): directory to save model.\n",
    "- max_epoch (int): maximum epoch.\n",
    "- start_epoch (int, optional): starting epoch. Default is 0.\n",
    "- print_freq (int, optional): print_frequency. Default is 10.\n",
    "- fixbase_epoch (int, optional): number of epochs to train ``open_layers`` (new layers)\n",
    "    while keeping base layers frozen. Default is 0. ``fixbase_epoch`` is counted\n",
    "    in ``max_epoch``.\n",
    "- open_layers (str or list, optional): layers (attribute names) open for training.\n",
    "- start_eval (int, optional): from which epoch to start evaluation. Default is 0.\n",
    "- eval_freq (int, optional): evaluation frequency. Default is -1 (meaning evaluation\n",
    "    is only performed at the end of training).\n",
    "- test_only (bool, optional): if True, only runs evaluation on test datasets.\n",
    "    Default is False.\n",
    "- dist_metric (str, optional): distance metric used to compute distance matrix\n",
    "    between query and gallery. Default is \"euclidean\".\n",
    "- normalize_feature (bool, optional): performs L2 normalization on feature vectors before\n",
    "    computing feature distance. Default is False.\n",
    "- visrank (bool, optional): visualizes ranked results. Default is False. It is recommended to\n",
    "    enable ``visrank`` when ``test_only`` is True. The ranked images will be saved to\n",
    "    \"save_dir/visrank_dataset\", e.g. \"save_dir/visrank_market1501\".\n",
    "- visrank_topk (int, optional): top-k ranked images to be visualized. Default is 10.\n",
    "- use_metric_cuhk03 (bool, optional): use single-gallery-shot setting for cuhk03.\n",
    "    Default is False. This should be enabled when using cuhk03 classic split.\n",
    "- ranks (list, optional): cmc ranks to be computed. Default is [1, 5, 10, 20].\n",
    "- rerank (bool, optional): uses person re-ranking (by Zhong et al. CVPR'17).\n",
    "    Default is False. This is only enabled when test_only=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a96f051-f716-4354-9930-1c63055dbaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating market1501 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 3368-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 15913-by-2048 matrix\n",
      "Speed: 5.1423 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 2.4%\n",
      "CMC curve\n",
      "Rank-1  : 8.1%\n",
      "Rank-5  : 16.4%\n",
      "Rank-10 : 22.5%\n",
      "Rank-20 : 29.3%\n",
      "# query: 3368\n",
      "# gallery 15913\n",
      "Visualizing top-20 ranks ...\n",
      "- done 100/3368\n",
      "- done 200/3368\n",
      "- done 300/3368\n",
      "- done 400/3368\n",
      "- done 500/3368\n",
      "- done 600/3368\n",
      "- done 700/3368\n",
      "- done 800/3368\n",
      "- done 900/3368\n",
      "- done 1000/3368\n",
      "- done 1100/3368\n",
      "- done 1200/3368\n",
      "- done 1300/3368\n",
      "- done 1400/3368\n",
      "- done 1500/3368\n",
      "- done 1600/3368\n",
      "- done 1700/3368\n",
      "- done 1800/3368\n",
      "- done 1900/3368\n",
      "- done 2000/3368\n",
      "- done 2100/3368\n",
      "- done 2200/3368\n",
      "- done 2300/3368\n",
      "- done 2400/3368\n",
      "- done 2500/3368\n",
      "- done 2600/3368\n",
      "- done 2700/3368\n",
      "- done 2800/3368\n",
      "- done 2900/3368\n",
      "- done 3000/3368\n",
      "- done 3100/3368\n",
      "- done 3200/3368\n",
      "- done 3300/3368\n",
      "Done. Images have been saved to \"log/resnet50/visrank_market1501\" ...\n",
      "CPU times: user 50min 47s, sys: 17min 41s, total: 1h 8min 28s\n",
      "Wall time: 18min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "engine.run(\n",
    "    save_dir=\"log/resnet50\",\n",
    "    # max_epoch=60,\n",
    "    # eval_freq=10,\n",
    "    # print_freq=10,\n",
    "    test_only=True,\n",
    "    visrank=True,\n",
    "    # visrank_topk=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0abf3-38b4-495f-8ee5-234918c98581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
